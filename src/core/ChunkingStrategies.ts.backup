/**
 * Chunking Strategies - Different approaches for splitting data based on plugin types
 * 
 * This module provides various strategies for intelligently chunking different
 * types of data to stay within context window limits while preserving meaning.
 */

import { 
  ChunkingStrategyType, 
  Chunk, 
  ChunkingError 
} from '../types/chunking-types.js';

export interface ChunkingStrategy {
  readonly type: ChunkingStrategyType;
  readonly name: string;
  readonly description: string;
  
  chunk(data: any, maxTokensPerChunk: number, metadata?: any): Promise<Chunk[]>;
  merge(chunks: Chunk[], results: any[]): Promise<any>;
}

/**
 * Base chunking strategy with common functionality
 */
export abstract class BaseChunkingStrategy implements ChunkingStrategy {
  abstract readonly type: ChunkingStrategyType;
  abstract readonly name: string;
  abstract readonly description: string;

  abstract chunk(data: any, maxTokensPerChunk: number, metadata?: any): Promise<Chunk[]>;
  abstract merge(chunks: Chunk[], results: any[]): Promise<any>;

  protected generateChunkId(index: number, totalChunks: number): string {
    return `chunk_${index.toString().padStart(3, '0')}_of_${totalChunks.toString().padStart(3, '0')}`;
  }

  protected estimateTokens(content: string): number {
    // Simple estimation: ~4 characters per token
    return Math.ceil(content.length / 4);
  }

  protected createChunk(
    id: string,
    index: number,
    totalChunks: number,
    content: any,
    originalSize: number,
    estimatedTokens: number,
    metadata?: any
  ): Chunk {
    return {
      id,
      index,
      totalChunks,
      content,
      metadata: {
        originalSize,
        estimatedTokens,
        ...metadata
      }
    };
  }
}

/**
 * Token-based chunking - Split content to stay within token limits
 */
export class TokenBasedStrategy extends BaseChunkingStrategy {
  readonly type = ChunkingStrategyType.TOKEN_BASED;
  readonly name = 'Token-Based Chunking';
  readonly description = 'Splits content based on estimated token count with overlap preservation';

  async chunk(data: any, maxTokensPerChunk: number, metadata?: any): Promise<Chunk[]> {
    if (typeof data !== 'string') {
      data = JSON.stringify(data, null, 2);
    }

    const chunks: Chunk[] = [];
    const overlapSize = Math.floor(maxTokensPerChunk * 0.1); // 10% overlap
    const effectiveChunkSize = maxTokensPerChunk - overlapSize;
    
    // Convert token limit to approximate character count
    const maxCharsPerChunk = effectiveChunkSize * 4;
    const overlapChars = overlapSize * 4;
    
    let currentPosition = 0;
    let chunkIndex = 0;
    
    while (currentPosition < data.length) {
      const endPosition = Math.min(currentPosition + maxCharsPerChunk, data.length);
      let content = data.slice(currentPosition, endPosition);
      
      // Add overlap from previous chunk (except for first chunk)
      if (chunkIndex > 0 && currentPosition >= overlapChars) {
        const overlapContent = data.slice(currentPosition - overlapChars, currentPosition);
        content = overlapContent + content;
      }
      
      const estimatedTokens = this.estimateTokens(content);
      chunks.push(this.createChunk(
        this.generateChunkId(chunkIndex, 0), // We'll update total later
        chunkIndex,
        0, // We'll update total later
        content,
        data.length,
        estimatedTokens,
        { 
          overlap: chunkIndex > 0 ? overlapChars : 0,
          boundaries: { start: currentPosition, end: endPosition },
          ...metadata 
        }
      ));
      
      currentPosition = endPosition;
      chunkIndex++;
    }
    
    // Update total chunks in all chunk objects
    const totalChunks = chunks.length;
    chunks.forEach((chunk, index) => {
      chunk.totalChunks = totalChunks;
      chunk.id = this.generateChunkId(index, totalChunks);
    });
    
    return chunks;
  }

  async merge(chunks: Chunk[], results: any[]): Promise<any> {
    if (results.length === 0) return null;
    if (results.length === 1) return results[0];

    // For token-based chunking, we typically concatenate string results
    // or merge objects intelligently
    const firstResult = results[0];
    
    if (typeof firstResult === 'string') {
      return results.join('\n\n--- Chunk Boundary ---\n\n');
    }
    
    if (Array.isArray(firstResult)) {
      return results.flat();
    }
    
    if (typeof firstResult === 'object' && firstResult !== null) {
      const merged = {};
      for (const result of results) {
        Object.assign(merged, result);
      }
      return merged;
    }
    
    return results;
  }
}

/**
 * File-based chunking - Split file lists into manageable batches
 */
export class FileBasedStrategy extends BaseChunkingStrategy {
  readonly type = ChunkingStrategyType.FILE_BASED;
  readonly name = 'File-Based Chunking';
  readonly description = 'Splits file lists into batches for processing';

  async chunk(data: any, maxTokensPerChunk: number, metadata?: any): Promise<Chunk[]> {
    let files: string[] = [];
    
    if (Array.isArray(data)) {
      files = data.filter(item => typeof item === 'string');
    } else if (typeof data === 'object' && data.files) {
      files = Array.isArray(data.files) ? data.files : [data.files];
    } else if (typeof data === 'string') {
      // Assume it's a single file path
      files = [data];
    } else {
      throw new ChunkingError('file_chunking', 'Invalid data format for file-based chunking');
    }

    if (files.length === 0) {
      throw new ChunkingError('file_chunking', 'No files found to chunk');
    }

    // Estimate files per chunk based on token limit
    // Assume average file path ~50 chars, plus processing overhead
    const estimatedTokensPerFile = 500; // Conservative estimate for file processing
    const filesPerChunk = Math.max(1, Math.floor(maxTokensPerChunk / estimatedTokensPerFile));
    
    const chunks: Chunk[] = [];
    let chunkIndex = 0;
    
    for (let i = 0; i < files.length; i += filesPerChunk) {
      const chunkFiles = files.slice(i, i + filesPerChunk);
      const estimatedTokens = chunkFiles.length * estimatedTokensPerFile;
      
      chunks.push(this.createChunk(
        this.generateChunkId(chunkIndex, 0),
        chunkIndex,
        0,
        typeof data === 'object' ? { ...data, files: chunkFiles } : chunkFiles,
        files.length,
        estimatedTokens,
        { 
          fileCount: chunkFiles.length,
          ...metadata 
        }
      ));
      
      chunkIndex++;
    }
    
    // Update total chunks
    const totalChunks = chunks.length;
    chunks.forEach((chunk, index) => {
      chunk.totalChunks = totalChunks;
      chunk.id = this.generateChunkId(index, totalChunks);
    });
    
    return chunks;
  }

  async merge(chunks: Chunk[], results: any[]): Promise<any> {
    if (results.length === 0) return null;
    if (results.length === 1) return results[0];

    // Merge file-based results
    const merged = {
      summary: {
        totalFiles: 0,
        totalChunks: results.length,
        processingTime: Date.now()
      },
      results: []
    };

    for (let i = 0; i < results.length; i++) {
      const result = results[i];
      const chunk = chunks[i];
      
      merged.results.push({
        chunkId: chunk.id,
        fileCount: chunk.metadata.fileCount,
        result
      });
      
      merged.summary.totalFiles += chunk.metadata.fileCount || 0;
    }

    return merged;
  }
}

/**
 * Function-based chunking - Split code analysis by functions/methods
 */
export class FunctionBasedStrategy extends BaseChunkingStrategy {
  readonly type = ChunkingStrategyType.FUNCTION_BASED;
  readonly name = 'Function-Based Chunking';
  readonly description = 'Splits code analysis by functions or logical boundaries';

  async chunk(data: any, maxTokensPerChunk: number, metadata?: any): Promise<Chunk[]> {
    let code: string;
    
    if (typeof data === 'string') {
      code = data;
    } else if (typeof data === 'object' && data.code) {
      code = data.code;
    } else {
      throw new ChunkingError('function_chunking', 'Invalid data format for function-based chunking');
    }

    // Simple function detection (can be enhanced with proper AST parsing)
    const functionRegex = /(?:function\s+\w+|const\s+\w+\s*=|class\s+\w+|def\s+\w+|public\s+\w+|private\s+\w+)/g;
    const lines = code.split('\n');
    const functionBoundaries: number[] = [0];
    
    for (let i = 0; i < lines.length; i++) {
      if (functionRegex.test(lines[i])) {
        functionBoundaries.push(i);
      }
    }
    
    functionBoundaries.push(lines.length);
    
    const chunks: Chunk[] = [];
    let chunkIndex = 0;
    let currentChunk: string[] = [];
    let currentTokens = 0;
    
    for (let i = 1; i < functionBoundaries.length; i++) {
      const functionLines = lines.slice(functionBoundaries[i - 1], functionBoundaries[i]);
      const functionCode = functionLines.join('\n');
      const functionTokens = this.estimateTokens(functionCode);
      
      // If adding this function would exceed the limit, finalize current chunk
      if (currentTokens + functionTokens > maxTokensPerChunk && currentChunk.length > 0) {
        const chunkContent = currentChunk.join('\n');
        chunks.push(this.createChunk(
          this.generateChunkId(chunkIndex, 0),
          chunkIndex,
          0,
          typeof data === 'object' ? { ...data, code: chunkContent } : chunkContent,
          code.length,
          currentTokens,
          { 
            functionCount: this.countFunctions(chunkContent),
            ...metadata 
          }
        ));
        
        currentChunk = [];
        currentTokens = 0;
        chunkIndex++;
      }
      
      currentChunk.push(...functionLines);
      currentTokens += functionTokens;
    }
    
    // Add remaining content as final chunk
    if (currentChunk.length > 0) {
      const chunkContent = currentChunk.join('\n');
      chunks.push(this.createChunk(
        this.generateChunkId(chunkIndex, 0),
        chunkIndex,
        0,
        typeof data === 'object' ? { ...data, code: chunkContent } : chunkContent,
        code.length,
        currentTokens,
        { 
          functionCount: this.countFunctions(chunkContent),
          ...metadata 
        }
      ));
    }
    
    // Update total chunks
    const totalChunks = chunks.length;
    chunks.forEach((chunk, index) => {
      chunk.totalChunks = totalChunks;
      chunk.id = this.generateChunkId(index, totalChunks);
    });
    
    return chunks;
  }

  private countFunctions(code: string): number {
    const functionRegex = /(?:function\s+\w+|const\s+\w+\s*=|class\s+\w+|def\s+\w+)/g;
    return (code.match(functionRegex) || []).length;
  }

  async merge(chunks: Chunk[], results: any[]): Promise<any> {
    if (results.length === 0) return null;
    if (results.length === 1) return results[0];

    // Merge function analysis results
    const merged = {
      summary: {
        totalChunks: results.length,
        totalFunctions: 0,
        analysisType: 'function-based'
      },
      functions: [],
      issues: [],
      suggestions: [],
      metrics: {
        complexity: 0,
        maintainability: 0
      }
    };

    for (let i = 0; i < results.length; i++) {
      const result = results[i];
      const chunk = chunks[i];
      
      if (result.functions) merged.functions.push(...result.functions);
      if (result.issues) merged.issues.push(...result.issues);
      if (result.suggestions) merged.suggestions.push(...result.suggestions);
      
      merged.summary.totalFunctions += chunk.metadata.functionCount || 0;
      
      if (result.metrics) {
        merged.metrics.complexity += result.metrics.complexity || 0;
        merged.metrics.maintainability += result.metrics.maintainability || 0;
      }
    }
    
    // Average the metrics
    if (results.length > 0) {
      merged.metrics.complexity /= results.length;
      merged.metrics.maintainability /= results.length;
    }

    return merged;
  }
}

/**
 * Semantic chunking - Split based on meaning and context boundaries
 */
export class SemanticBasedStrategy extends BaseChunkingStrategy {
  readonly type = ChunkingStrategyType.SEMANTIC_BASED;
  readonly name = 'Semantic-Based Chunking';
  readonly description = 'Splits content based on semantic boundaries and context';

  async chunk(data: any, maxTokensPerChunk: number, metadata?: any): Promise<Chunk[]> {
    // This is a simplified semantic chunking - in production, you'd use
    // more sophisticated NLP techniques to identify semantic boundaries
    
    let text: string;
    if (typeof data === 'string') {
      text = data;
    } else {
      text = JSON.stringify(data, null, 2);
    }

    // Split by paragraphs and sentences for semantic boundaries
    const paragraphs = text.split(/\n\s*\n/);
    const chunks: Chunk[] = [];
    let chunkIndex = 0;
    let currentChunk: string[] = [];
    let currentTokens = 0;
    
    for (const paragraph of paragraphs) {
      const paragraphTokens = this.estimateTokens(paragraph);
      
      // If adding this paragraph would exceed the limit, finalize current chunk
      if (currentTokens + paragraphTokens > maxTokensPerChunk && currentChunk.length > 0) {
        const chunkContent = currentChunk.join('\n\n');
        chunks.push(this.createChunk(
          this.generateChunkId(chunkIndex, 0),
          chunkIndex,
          0,
          chunkContent,
          text.length,
          currentTokens,
          { 
            paragraphCount: currentChunk.length,
            ...metadata 
          }
        ));
        
        currentChunk = [];
        currentTokens = 0;
        chunkIndex++;
      }
      
      currentChunk.push(paragraph);
      currentTokens += paragraphTokens;
    }
    
    // Add remaining content
    if (currentChunk.length > 0) {
      const chunkContent = currentChunk.join('\n\n');
      chunks.push(this.createChunk(
        this.generateChunkId(chunkIndex, 0),
        chunkIndex,
        0,
        chunkContent,
        text.length,
        currentTokens,
        { 
          paragraphCount: currentChunk.length,
          ...metadata 
        }
      ));
    }
    
    // Update total chunks
    const totalChunks = chunks.length;
    chunks.forEach((chunk, index) => {
      chunk.totalChunks = totalChunks;
      chunk.id = this.generateChunkId(index, totalChunks);
    });
    
    return chunks;
  }

  async merge(chunks: Chunk[], results: any[]): Promise<any> {
    if (results.length === 0) return null;
    if (results.length === 1) return results[0];

    // Semantic merging focuses on maintaining meaning across chunks
    const merged = {
      summary: `Analysis of ${chunks.length} semantic chunks`,
      insights: [],
      themes: new Set(),
      conclusion: ''
    };

    for (const result of results) {
      if (typeof result === 'string') {
        merged.insights.push(result);
      } else if (result.insights) {
        merged.insights.push(...result.insights);
      }
      
      if (result.themes) {
        result.themes.forEach(theme => merged.themes.add(theme));
      }
    }

    merged.conclusion = `Analysis reveals ${merged.themes.size} main themes across ${chunks.length} semantic sections.`;
    
    return {
      ...merged,
      themes: Array.from(merged.themes)
    };
  }
}

/**
 * Strategy Factory - Creates appropriate chunking strategy based on plugin type
 */
export class ChunkingStrategyFactory {
  private static strategies = new Map<string, ChunkingStrategy>([
    ['token', new TokenBasedStrategy()],
    ['file', new FileBasedStrategy()],
    ['function', new FunctionBasedStrategy()],
    ['semantic', new SemanticBasedStrategy()]
  ]);

  static getStrategy(pluginName: string, preferredType?: ChunkingStrategyType): ChunkingStrategy {
    // Plugin-specific strategy selection
    if (pluginName.includes('file') || pluginName.includes('pattern') || pluginName.includes('project')) {
      return this.strategies.get('file')!;
    }
    
    if (pluginName.includes('analyze') && pluginName.includes('code')) {
      return this.strategies.get('function')!;
    }
    
    if (pluginName.includes('trace') || pluginName.includes('execution')) {
      return this.strategies.get('semantic')!;
    }
    
    // Use preferred type if specified
    if (preferredType) {
      const strategyKey = preferredType.toString();
      if (this.strategies.has(strategyKey)) {
        return this.strategies.get(strategyKey)!;
      }
    }
    
    // Default to token-based chunking
    return this.strategies.get('token')!;
  }

  static getAllStrategies(): ChunkingStrategy[] {
    return Array.from(this.strategies.values());
  }

  static registerStrategy(key: string, strategy: ChunkingStrategy): void {
    this.strategies.set(key, strategy);
  }
}
